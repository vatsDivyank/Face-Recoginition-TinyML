{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "User_not_User_FineTuned.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15IvGQpXRCtxCZpSBsNajRN8ZWvEPdqGm",
      "authorship_tag": "ABX9TyMYESGa0OSVa3HexJDiTzYC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vatsDivyank/Face-Recoginition-TinyML/blob/main/User_not_User_FineTuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU7IPg1ona3k"
      },
      "source": [
        "!pip install tensorflow==2.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZkJdVYSDwL"
      },
      "source": [
        "\n",
        "\n",
        "Include Libraries and Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjUhQLJRwgmB"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRCikA1HvWMy",
        "outputId": "b8fd1ed9-4250-4d61-e7be-a10413ee78a9"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzCeaN8eSK7g"
      },
      "source": [
        "Copying the Preprocessing Image from Google Drive to /content\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uyDEQa30vYT"
      },
      "source": [
        "!cp \"/content/drive/MyDrive/Preprocessing_images.py\" \"/content\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgsggFjp05Lh"
      },
      "source": [
        "from Preprocessing_images import DivyankNotDivyank"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TRSwg-Y06BD"
      },
      "source": [
        "MODELS_DIR = os.path.abspath(\"/content/drive/MyDrive/MODEL_DIR\")\n",
        "MODEL_FILE_PATH_PB= os.path.join(MODELS_DIR, \"divyank_not_divyank_FineTuned_Mobilenet.pb\")\n",
        "MODEL_FILE_PATH_FULL_INTEGER= os.path.join(MODELS_DIR, \"divyank_not_divyank_FineTuned_Mobilenet_FULL_INTEGER.tflite\")\n",
        "MODEL_FILE_PATH_h5= os.path.join(MODELS_DIR, \"divyank_not_divyank_FineTuned_Mobilenet.h5\")\n",
        "\n",
        "MODEL_TFLITE = os.path.join(MODELS_DIR, 'divyank_not_divyank_FineTuned_Mobilenet.tflite')\n",
        "MODEL_TFLITE_MICRO = os.path.join(MODELS_DIR , 'divyank_not_divyank_Mobilenet.cc')\n",
        "\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "\n",
        "LOGS_DIR = os.path.abspath(\"/content/drive/MyDrive/Logs_Dir/logs\")\n",
        "if not os.path.exists(LOGS_DIR):\n",
        "    os.mkdir(LOGS_DIR)\n",
        "\n",
        "MODEL_LOG_DIR = os.path.join(LOGS_DIR , \"divyank_not_divyank\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpjtBnjpSXWO"
      },
      "source": [
        "Here, we try to create a simple Model and follow the process of training, testing, and converting the Model to full_integer_quantized version and make it work on Microcontroller."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEW92DZ7TbLP"
      },
      "source": [
        "Definition of an own model, which can be trained for face recoginition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yoRGkjE1VF_"
      },
      "source": [
        "IMAGENET_SIZE = 128\n",
        "IMAGENET_DEPTH = 3\n",
        "IMAGENET_SHAPE = (IMAGENET_SIZE, IMAGENET_SIZE,IMAGENET_DEPTH)\n",
        "\n",
        "def build_model(img_shape, num_classes) -> Model:\n",
        "    base_model = MobileNet(\n",
        "        input_shape = IMAGENET_SHAPE,\n",
        "        alpha = 0.25,\n",
        "        #depth_multiplier = 0.5, #Only for MobileNet\n",
        "        include_top=False,\n",
        "        weights=\"imagenet\",\n",
        "        pooling =max\n",
        "    )\n",
        "\n",
        "    num_layers = len(base_model.layers)\n",
        "    print(f\"Number of layers in the base model: {num_layers}\")\n",
        "    fine_tune_at = num_layers - 86 \n",
        "    for layer in base_model.layers[:fine_tune_at]:\n",
        "        layer.trainable = False,\n",
        "        \n",
        "\n",
        "    input_img = Input(shape=img_shape)\n",
        "    x = Rescaling(scale=1./127.5, offset=-1.0)(input_img)\n",
        "    x = Resizing(height=IMAGENET_SIZE, width=IMAGENET_SIZE)(x)\n",
        "    x = Concatenate()([x, x, x])\n",
        "    x = base_model(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(units=num_classes)(x)\n",
        "    y_pred = Activation(\"softmax\")(x)\n",
        "\n",
        "    model = Model(\n",
        "        inputs=[input_img],\n",
        "        outputs=[y_pred]\n",
        "    )\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoVf_CofErRh"
      },
      "source": [
        "\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir {MODEL_LOG_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6loiteeJguZ"
      },
      "source": [
        "tensorboard --inspect --logdir {MODEL_LOG_DIR}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzVDWf5w1mMl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "646c6ceb-36b0-437a-d1b1-f12edf098790"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    data = DivyankNotDivyank()\n",
        "    data.data_augmentation(augment_size= 1000)\n",
        "    x_train, x_val_,y_train_, y_val_ = data.get_splitted_train_validation_set()\n",
        "    x_test , y_test = data.get_test_set()\n",
        "\n",
        "    img_shape = data.img_shape\n",
        "    num_classes = data.num_classes\n",
        "\n",
        "\n",
        "    opt = Adam(learning_rate=0.00001)#7e-4\n",
        "\n",
        "\n",
        "    # Global params\n",
        "    epochs = 10\n",
        "    batch_size = 128\n",
        "\n",
        "\n",
        "\n",
        "    model = build_model(\n",
        "        img_shape,\n",
        "        num_classes,\n",
        "    )\n",
        "    opt = Adam(learning_rate=0.00001)#7e-4\n",
        "    \n",
        "    \n",
        "    # tb_callback = TensorBoard(\n",
        "    #     log_dir=MODEL_LOG_DIR,\n",
        "    #     histogram_freq=1,\n",
        "    #     write_graph = True\n",
        "    # )\n",
        "  \n",
        "    model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=opt,\n",
        "    metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        x=x_train_ ,\n",
        "        y= y_train_,\n",
        "        verbose=1,\n",
        "        epochs=epochs,\n",
        "       # callbacks=[tb_callback],\n",
        "        validation_data=(x_val_, y_val_),\n",
        "    )\n",
        "    model.save(MODEL_FILE_PATH_PB)\n",
        "    model.save(MODEL_FILE_PATH_h5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9b25824d7adc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     model = build_model(\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mimg_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'build_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvjDxECu0F-K",
        "outputId": "2060b689-70f4-49a0-b9d7-ab50ccc26076"
      },
      "source": [
        "score = model.evaluate(\n",
        "    x_test, y_test,\n",
        "    verbose = 0,\n",
        "    batch_size = batch_size\n",
        ")\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.2733690738677979, 0.7791932225227356]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3iicT_PHkS1",
        "outputId": "17d06dbb-8f09-4d04-f936-c8f3b476764b"
      },
      "source": [
        "\n",
        "#Converting the Model to Tensorflow Lite format with float16 quantization\n",
        "converter_float16 = tf.lite.TFLiteConverter.from_saved_model(MODEL_FILE_PATH_PB)\n",
        "converter_float16.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter_float16.target_spec.supported_types = [tf.float16]\n",
        "tflite_model_float16 = converter_float16.convert()\n",
        "\n",
        "#Save to disk\n",
        "model_float16 = (open(\"model_quant16.tflite\",\"wb\").write(tflite_model_float16))/1024\n",
        "print(\"float16 Model size %d KB\" % model_float16)\n",
        "\n",
        "#Converting the Model to the Tensorflow Lite format with dynamic range Quantization\n",
        "converter_dynamic = tf.lite.TFLiteConverter.from_saved_model(MODEL_FILE_PATH_PB)\n",
        "converter_dynamic.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model_dynamic =  converter_dynamic.convert()\n",
        "\n",
        "#Save to Disk\n",
        "model_dynamic_size = (open(\"model_dynamic.tflite\",\"wb\").write(tflite_model_dynamic))/1024\n",
        "print(\"Dynamic Model size %d KB\" % model_dynamic_size)\n",
        "\n",
        "\n",
        "#Converting the Model into Tensorflow Lite format with full Interger quantization\n",
        "\n",
        "#This Quantization requires creation of representative Dataset\n",
        "images = tf.cast(x_test, tf.float32)\n",
        "test_data = tf.data.Dataset.from_tensor_slices(images).batch(1)\n",
        "def representative_dataset_gen():\n",
        "  for input in test_data.take(100):\n",
        "    yield[input]\n",
        "\n",
        "converter_full_integer = tf.lite.TFLiteConverter.from_saved_model(MODEL_FILE_PATH_PB)\n",
        "converter_full_integer.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "converter_full_integer.representative_dataset = representative_dataset_gen\n",
        "converter_full_integer.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter_full_integer.inference_input_type = tf.int8\n",
        "converter_full_integer.inference_output_type = tf.int8 ## Check hier with tf.int8\n",
        "tflite_model_full_integer = converter_full_integer.convert()\n",
        "\n",
        "# Save to disk\n",
        "model_full_integer=(open(\"model_full_integer.tflite\", \"wb\").write(tflite_model_full_integer))/ 1024\n",
        "print(\"Full Integer Model Size %d KB\" % model_full_integer)\n",
        "\n",
        "# float16 Model size 429 KB\n",
        "# Dynamic Model size 284 KB\n",
        "# Full Integer Model Size 315 KB"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "float16 Model size 106 KB\n",
            "Dynamic Model size 55 KB\n",
            "Full Integer Model Size 55 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-uzURADp3M3",
        "outputId": "279e8361-2b54-4a28-a370-8ace5c57cd8e"
      },
      "source": [
        "interpreter = tf.lite.Interpreter(model_path='/content/model_full_integer.tflite')\n",
        "input_type = interpreter.get_input_details()[0]['dtype']\n",
        "print('input:', input_type)\n",
        "output_type = interpreter.get_output_details()[0]['dtype']\n",
        "print('output:', output_type)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: <class 'numpy.int8'>\n",
            "output: <class 'numpy.int8'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP8ObNJISKFm"
      },
      "source": [
        "# Helper function to run the inference on a TFLite Model\n",
        "def run_tflite_model(tflite_file, test_image_indices):\n",
        "  global test_images\n",
        "\n",
        "  #Initialize the interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_path='/content/model_full_integer.tflite')\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  predictions = np.zeros((len(test_image_indices),), dtype=int)\n",
        "  for i, test_image_index in enumerate (test_image_indices):\n",
        "    test_image = test_images[test_image_index]\n",
        "    test_label = test_labels[test_image_index]\n",
        "\n",
        "    #Checking if the input data is Quantized, then rescale input data to uint8\n",
        "    if input_details['dtype'] == np.uint8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "    \n",
        "    if input_details['dtype'] == np.uint8:\n",
        "      input_scale, input_zero_point = input_details[\"quantization\"]\n",
        "      test_image = test_image / input_scale + input_zero_point\n",
        "\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
        "    interpreter.set_tensor(input_details[\"index\"], test_image)\n",
        "    interpreter.invoke()\n",
        "    output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
        "\n",
        "    predictions[i] = output.argmax()\n",
        "  return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoDq9dBCx2vb",
        "outputId": "1df36455-42a4-497a-aeb2-869e789672d5"
      },
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file\n",
        "!xxd -i \"model_full_integer.tflite\" > {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.142)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to ppa.launchpad.net (91.189.95.85)] \r                                                                               \rIgn:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:13 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzA7ffmXxsvG"
      },
      "source": [
        "!cat {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "z2CKhbzR_Oej",
        "outputId": "5b60bcba-3e8f-40d7-d7f3-8126a66c9603"
      },
      "source": [
        "  model.load_weights (MODEL_FILE_PATH_h5)\n",
        "  TEST_PHOTO_DIR = os.path.abspath(\"/content/drive/MyDrive/Folder_to_test_photos\")\n",
        "  image_names = [f for f in os.listdir(TEST_PHOTO_DIR) if \".jpg\"in f or\".jpeg\" in f or \".png\" in f]\n",
        "  class_names = [\"Divyank\", \"not_Divyank\"]\n",
        "  for image_file_name in image_names:\n",
        "        image_file_path = os.path.join(TEST_PHOTO_DIR, image_file_name)\n",
        "        print(image_file_path)\n",
        "        x = data.load_and_preprocess_custom_image(image_file_path)\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        y_pred = model.predict(x)[0]\n",
        "        y_pred_class_idx = np.argmax(y_pred)\n",
        "        y_pred_prob = y_pred[ y_pred_class_idx]\n",
        "        y_pred_class_name=class_names[y_pred_class_idx]\n",
        "        plt.imshow(x.reshape(96, 96, 1))\n",
        "        plt.title(f\"Pred class:{y_pred_class_name}, Prob:{y_pred_prob}\")\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Folder_to_test_photos/1 (22).jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d1d6e109f83e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mimage_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST_PHOTO_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_preprocess_custom_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load_and_preprocess_custom_image() takes 1 positional argument but 2 were given"
          ]
        }
      ]
    }
  ]
}